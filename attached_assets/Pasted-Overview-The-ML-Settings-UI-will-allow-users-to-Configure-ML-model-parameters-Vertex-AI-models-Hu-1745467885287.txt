Overview
The ML Settings UI will allow users to:
Configure ML model parameters (Vertex AI models, HuggingFace metrics)
Visualize optimization experiments and model performance
Fine-tune meta-learning components and optimization strategies
Monitor token usage and cost metrics


┌───────────────────────────────────────────────────────────────┐
│                    FastAPI Application                        │
│                    (Main Entry Point)                         │
└───────────────────────────┬───────────────────────────────────┘
                            │
             ┌──────────────┴──────────────┐
             │                             │
┌────────────▼─────────────┐  ┌────────────▼─────────────┐
│    Flask Dashboard       │  │      Prefect Flows       │
│   (Admin & ML Settings)  │  │ (Workflow Orchestration) │
└────────────┬─────────────┘  └────────────┬─────────────┘
             │                              │
             └──────────────┬──────────────┘
                            │
                 ┌──────────▼──────────┐
                 │   Shared Services   │
                 │ (Auth, DB, Caching) │
                 └─────────────────────┘

         NEW ML SETTINGS UI COMPONENTS
┌─────────────────────────────────────────────┐
│ ┌─────────────────┐  ┌─────────────────┐    │
│ │  Model Config   │  │ Metric Settings │    │
│ └─────────────────┘  └─────────────────┘    │
│                                             │
│ ┌─────────────────┐  ┌─────────────────┐    │
│ │  Experiment     │  │ Meta-Learning   │    │
│ │  Visualization  │  │ Configuration   │    │
│ └─────────────────┘  └─────────────────┘    │
└─────────────────────────────────────────────┘

Modelsettings: 

# src/app/db/ml_models.py
from sqlalchemy import Column, String, Integer, Float, Boolean, JSON, ForeignKey
from sqlalchemy.orm import relationship
from src.app.db.database import Base
import uuid

class ModelConfiguration(Base):
    __tablename__ = "model_configurations"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String, nullable=False)
    primary_model = Column(String, nullable=False)  # e.g., "gemini-1.5-flash"
    optimizer_model = Column(String, nullable=False)  # e.g., "gemini-1.5-pro"
    temperature = Column(Float, default=0.0)
    max_tokens = Column(Integer, default=1024)
    top_p = Column(Float, default=1.0)
    top_k = Column(Integer, default=40)
    is_default = Column(Boolean, default=False)
    user_id = Column(String, ForeignKey("users.id"))
    
    user = relationship("User", back_populates="model_configs")

class MetricConfiguration(Base):
    __tablename__ = "metric_configurations"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String, nullable=False)
    metrics = Column(JSON, nullable=False)  # e.g., ["exact_match", "bleu"]
    metric_weights = Column(JSON, default=dict)  # e.g., {"exact_match": 0.7, "bleu": 0.3}
    target_threshold = Column(Float, default=0.8)
    user_id = Column(String, ForeignKey("users.id"))
    
    user = relationship("User", back_populates="metric_configs")

class MetaLearningConfiguration(Base):
    __tablename__ = "meta_learning_configurations"
    
    id = Column(String, primary_key=True, default=lambda: str(uuid.uuid4()))
    name = Column(String, nullable=False)
    model_type = Column(String, default="xgboost")  # "xgboost", "random_forest", etc.
    hyperparameters = Column(JSON, default=dict)
    feature_selection = Column(JSON, default=dict)
    is_active = Column(Boolean, default=True)
    user_id = Column(String, ForeignKey("users.id"))
    
    user = relationship("User", back_populates="meta_learning_configs")

# Update User model to include relationships
class User(Base):
    # Existing columns and relationships...
    
    model_configs = relationship("ModelConfiguration", back_populates="user")
    metric_configs = relationship("MetricConfiguration", back_populates="user")
    meta_learning_configs = relationship("MetaLearningConfiguration", back_populates="user")

    # src/app/services/ml_settings_service.py
from sqlalchemy.orm import Session
from src.app.db.ml_models import ModelConfiguration, MetricConfiguration, MetaLearningConfiguration
from typing import Dict, Any, List, Optional

class MLSettingsService:
    def __init__(self, db: Session):
        self.db = db
    
    def get_model_configurations(self, user_id: str) -> List[Dict[str, Any]]:
        """Get all model configurations for a user"""
        configs = self.db.query(ModelConfiguration).filter(
            ModelConfiguration.user_id == user_id
        ).all()
        
        return [config.__dict__ for config in configs]
    
    def create_model_configuration(self, user_id: str, config_data: Dict[str, Any]) -> Dict[str, Any]:
        """Create a new model configuration"""
        config = ModelConfiguration(
            user_id=user_id,
            name=config_data.get("name", "Default Configuration"),
            primary_model=config_data.get("primary_model", "gemini-1.5-flash"),
            optimizer_model=config_data.get("optimizer_model", "gemini-1.5-pro"),
            temperature=config_data.get("temperature", 0.0),
            max_tokens=config_data.get("max_tokens", 1024),
            top_p=config_data.get("top_p", 1.0),
            top_k=config_data.get("top_k", 40),
            is_default=config_data.get("is_default", False)
        )
        
        if config.is_default:
            # If this config is set as default, unset any existing defaults
            existing_defaults = self.db.query(ModelConfiguration).filter(
                ModelConfiguration.user_id == user_id,
                ModelConfiguration.is_default == True
            ).all()
            
            for default_config in existing_defaults:
                default_config.is_default = False
                
        self.db.add(config)
        self.db.commit()
        self.db.refresh(config)
        
        return config.__dict__
    
    # Similar methods for metric and meta-learning configurations...
    
    def update_meta_learning_configuration(self, config_id: str, config_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Update a meta-learning configuration"""
        config = self.db.query(MetaLearningConfiguration).filter(
            MetaLearningConfiguration.id == config_id
        ).first()
        
        if not config:
            return None
            
        for key, value in config_data.items():
            if hasattr(config, key):
                setattr(config, key, value)
                
        self.db.commit()
        self.db.refresh(config)
        
        return config.__dict__

        # src/app/dashboard/ml_settings.py
from flask import Blueprint, render_template, request, jsonify, redirect, url_for
from flask_login import login_required, current_user
from src.app.services.ml_settings_service import MLSettingsService
from src.app.db.database import get_db

ml_settings_bp = Blueprint('ml_settings', __name__, url_prefix='/ml-settings')

@ml_settings_bp.route('/')
@login_required
def index():
    """Render the ML settings dashboard"""
    return render_template('ml_settings/index.html')

@ml_settings_bp.route('/models')
@login_required
def model_configurations():
    """Render the model configurations page"""
    db = next(get_db())
    service = MLSettingsService(db)
    configs = service.get_model_configurations(current_user.id)
    
    return render_template('ml_settings/models.html', configurations=configs)

@ml_settings_bp.route('/models/create', methods=['GET', 'POST'])
@login_required
def create_model_configuration():
    """Create a new model configuration"""
    if request.method == 'POST':
        db = next(get_db())
        service = MLSettingsService(db)
        
        config_data = {
            "name": request.form.get('name'),
            "primary_model": request.form.get('primary_model'),
            "optimizer_model": request.form.get('optimizer_model'),
            "temperature": float(request.form.get('temperature', 0.0)),
            "max_tokens": int(request.form.get('max_tokens', 1024)),
            "top_p": float(request.form.get('top_p', 1.0)),
            "top_k": int(request.form.get('top_k', 40)),
            "is_default": 'is_default' in request.form
        }
        
        service.create_model_configuration(current_user.id, config_data)
        return redirect(url_for('ml_settings.model_configurations'))
        
    return render_template('ml_settings/create_model.html')

# Similar routes for metrics, meta-learning, etc.

@ml_settings_bp.route('/meta-learning/train', methods=['POST'])
@login_required
def train_meta_model():
    """Train a new meta-learning model"""
    config_id = request.form.get('config_id')
    
    # Start a Celery task to train the model asynchronously
    from src.app.services.background_service import train_meta_model_task
    task = train_meta_model_task.delay(config_id, current_user.id)
    
    return jsonify({"status": "training_started", "task_id": task.id})

    <!-- src/app/templates/ml_settings/index.html -->
{% extends "base.html" %}

{% block content %}
<div class="ml-settings-dashboard">
  <h1>Machine Learning Settings</h1>
  
  <div class="card-grid">
    <div class="card">
      <h2>Model Configurations</h2>
      <p>Configure LLM models, parameters, and inference settings</p>
      <a href="{{ url_for('ml_settings.model_configurations') }}" class="btn">Manage Models</a>
    </div>
    
    <div class="card">
      <h2>Evaluation Metrics</h2>
      <p>Configure metrics, weights, and evaluation thresholds</p>
      <a href="{{ url_for('ml_settings.metric_configurations') }}" class="btn">Manage Metrics</a>
    </div>
    
    <div class="card">
      <h2>Meta-Learning</h2>
      <p>Configure and train meta-models for prompt quality prediction</p>
      <a href="{{ url_for('ml_settings.meta_learning_configurations') }}" class="btn">Manage Meta-Learning</a>
    </div>
    
    <div class="card">
      <h2>Experiment Visualization</h2>
      <p>Visualize experiment results and comparative performance</p>
      <a href="{{ url_for('ml_settings.experiment_visualization') }}" class="btn">View Experiments</a>
    </div>
  </div>
</div>
{% endblock %}
<!-- src/app/templates/ml_settings/models.html -->
{% extends "base.html" %}

{% block content %}
<div class="ml-settings-models">
  <h1>Model Configurations</h1>
  
  <a href="{{ url_for('ml_settings.create_model_configuration') }}" class="btn btn-primary">Create New Configuration</a>
  
  <table class="data-table">
    <thead>
      <tr>
        <th>Name</th>
        <th>Primary Model</th>
        <th>Optimizer Model</th>
        <th>Temperature</th>
        <th>Default</th>
        <th>Actions</th>
      </tr>
    </thead>
    <tbody>
      {% for config in configurations %}
      <tr>
        <td>{{ config.name }}</td>
        <td>{{ config.primary_model }}</td>
        <td>{{ config.optimizer_model }}</td>
        <td>{{ config.temperature }}</td>
        <td>{% if config.is_default %}✓{% endif %}</td>
        <td>
          <a href="{{ url_for('ml_settings.edit_model_configuration', config_id=config.id) }}" class="btn btn-sm">Edit</a>
          <a href="{{ url_for('ml_settings.delete_model_configuration', config_id=config.id) }}" class="btn btn-sm btn-danger"
             onclick="return confirm('Are you sure you want to delete this configuration?')">Delete</a>
        </td>
      </tr>
      {% endfor %}
    </tbody>
  </table>
</div>
{% endblock %}
<!-- src/app/templates/ml_settings/meta_learning.html -->
{% extends "base.html" %}

{% block content %}
<div class="ml-settings-meta-learning">
  <h1>Meta-Learning Configuration</h1>
  
  <a href="{{ url_for('ml_settings.create_meta_learning_configuration') }}" class="btn btn-primary">Create New Configuration</a>
  
  <table class="data-table">
    <thead>
      <tr>
        <th>Name</th>
        <th>Model Type</th>
        <th>Status</th>
        <th>Last Trained</th>
        <th>Performance</th>
        <th>Actions</th>
      </tr>
    </thead>
    <tbody>
      {% for config in configurations %}
      <tr>
        <td>{{ config.name }}</td>
        <td>{{ config.model_type }}</td>
        <td>{{ "Active" if config.is_active else "Inactive" }}</td>
        <td>{{ config.last_trained or "Never" }}</td>
        <td>{{ "%.2f" % config.performance if config.performance else "N/A" }}</td>
        <td>
          <a href="{{ url_for('ml_settings.edit_meta_learning_configuration', config_id=config.id) }}" class="btn btn-sm">Edit</a>
          <button class="btn btn-sm btn-primary train-btn" data-config-id="{{ config.id }}">Train</button>
          <a href="{{ url_for('ml_settings.delete_meta_learning_configuration', config_id=config.id) }}" class="btn btn-sm btn-danger"
             onclick="return confirm('Are you sure you want to delete this configuration?')">Delete</a>
        </td>
      </tr>
      {% endfor %}
    </tbody>
  </table>
  
  <div id="training-status" class="hidden">
    <h3>Training in Progress</h3>
    <div class="progress-bar">
      <div class="progress" style="width: 0%"></div>
    </div>
    <p class="status-text">Initializing training...</p>
  </div>
</div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const trainButtons = document.querySelectorAll('.train-btn');
  const trainingStatus = document.getElementById('training-status');
  const progressBar = document.querySelector('.progress');
  const statusText = document.querySelector('.status-text');
  
  trainButtons.forEach(button => {
    button.addEventListener('click', function() {
      const configId = this.getAttribute('data-config-id');
      
      // Disable all training buttons
      trainButtons.forEach(btn => btn.disabled = true);
      
      // Show training status
      trainingStatus.classList.remove('hidden');
      
      // Start training via API
      fetch("{{ url_for('ml_settings.train_meta_model') }}", {
        method: 'POST',
        headers: {
          'Content-Type': 'application/x-www-form-urlencoded',
          'X-CSRFToken': '{{ csrf_token() }}'
        },
        body: `config_id=${configId}`
      })
      .then(response => response.json())
      .then(data => {
        if (data.status === 'training_started') {
          // Poll for training status
          pollTrainingStatus(data.task_id);
        }
      })
      .catch(error => {
        console.error('Error starting training:', error);
        statusText.textContent = 'Error starting training. Please try again.';
        trainButtons.forEach(btn => btn.disabled = false);
      });
    });
  });
  
  function pollTrainingStatus(taskId) {
    const statusCheck = setInterval(() => {
      fetch(`/api/tasks/${taskId}`)
        .then(response => response.json())
        .then(data => {
          if (data.status === 'pending') {
            progressBar.style.width = '30%';
            statusText.textContent = 'Training in progress...';
          } else if (data.status === 'completed') {
            progressBar.style.width = '100%';
            statusText.textContent = 'Training completed successfully!';
            setTimeout(() => {
              window.location.reload();
            }, 2000);
            clearInterval(statusCheck);
          } else {
            progressBar.style.width = '100%';
            statusText.textContent = `Training failed: ${data.error}`;
            trainButtons.forEach(btn => btn.disabled = false);
            clearInterval(statusCheck);
          }
        })
        .catch(error => {
          console.error('Error checking status:', error);
          clearInterval(statusCheck);
          trainButtons.forEach(btn => btn.disabled = false);
        });
    }, 2000);
  }
});
</script>
{% endblock %}

<!-- src/app/templates/ml_settings/visualization.html -->
{% extends "base.html" %}

{% block extra_head %}
<script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
{% endblock %}

{% block content %}
<div class="ml-settings-visualization">
  <h1>Experiment Visualization</h1>
  
  <div class="filter-bar">
    <form id="filter-form">
      <div class="form-group">
        <label for="experiment-select">Experiment:</label>
        <select id="experiment-select" name="experiment_id">
          <option value="">Select an experiment</option>
          {% for experiment in experiments %}
          <option value="{{ experiment.id }}">{{ experiment.name }}</option>
          {% endfor %}
        </select>
      </div>
      
      <div class="form-group">
        <label for="metric-select">Metric:</label>
        <select id="metric-select" name="metric">
          <option value="exact_match_score">Exact Match</option>
          <option value="bleu_score">BLEU</option>
          <option value="rouge_l">ROUGE-L</option>
          <option value="bertscore">BERTScore</option>
        </select>
      </div>
      
      <button type="submit" class="btn">Apply Filters</button>
    </form>
  </div>
  
  <div class="chart-container">
    <canvas id="metrics-chart"></canvas>
  </div>
  
  <div class="prompt-comparison">
    <h2>Prompt Evolution</h2>
    <div id="prompt-versions"></div>
  </div>
</div>

<script>
document.addEventListener('DOMContentLoaded', function() {
  const filterForm = document.getElementById('filter-form');
  const metricsChart = document.getElementById('metrics-chart');
  const promptVersions = document.getElementById('prompt-versions');
  
  let chart = null;
  
  filterForm.addEventListener('submit', function(e) {
    e.preventDefault();
    
    const experimentId = document.getElementById('experiment-select').value;
    const metric = document.getElementById('metric-select').value;
    
    if (!experimentId) return;
    
    // Fetch experiment metrics
    fetch(`/api/v1/experiments/${experimentId}/metrics?metric=${metric}`)
      .then(response => response.json())
      .then(data => {
        renderMetricsChart(data, metric);
        renderPromptVersions(data.prompt_versions);
      })
      .catch(error => {
        console.error('Error fetching experiment data:', error);
      });
  });
  
  function renderMetricsChart(data, metricName) {
    const ctx = metricsChart.getContext('2d');
    
    // Format data for Chart.js
    const labels = data.metrics_history.map((_, index) => `Epoch ${index}`);
    const trainData = data.metrics_history.map(m => m[`train_${metricName}`]);
    const valData = data.metrics_history.map(m => m[`val_${metricName}`]);
    
    if (chart) {
      chart.destroy();
    }
    
    chart = new Chart(ctx, {
      type: 'line',
      data: {
        labels: labels,
        datasets: [
          {
            label: `Training ${metricName}`,
            data: trainData,
            borderColor: 'rgba(75, 192, 192, 1)',
            backgroundColor: 'rgba(75, 192, 192, 0.2)',
            tension: 0.1
          },
          {
            label: `Validation ${metricName}`,
            data: valData,
            borderColor: 'rgba(153, 102, 255, 1)',
            backgroundColor: 'rgba(153, 102, 255, 0.2)',
            tension: 0.1
          }
        ]
      },
      options: {
        responsive: true,
        scales: {
          y: {
            beginAtZero: true,
            max: 1.0
          }
        }
      }
    });
  }
  
  function renderPromptVersions(versions) {
    promptVersions.innerHTML = '';
    
    if (!versions || versions.length === 0) {
      promptVersions.innerHTML = '<p>No prompt versions available for this experiment.</p>';
      return;
    }
    
    // Create an accordion for prompt versions
    const accordion = document.createElement('div');
    accordion.className = 'accordion';
    
    versions.forEach((version, index) => {
      const panel = document.createElement('div');
      panel.className = 'accordion-panel';
      
      const header = document.createElement('div');
      header.className = 'accordion-header';
      header.textContent = `Version ${version.version} - Epoch ${index}`;
      
      const content = document.createElement('div');
      content.className = 'accordion-content';
      
      // Create diffable view
      const diffView = document.createElement('div');
      diffView.className = 'diff-view';
      
      const systemPrompt = document.createElement('div');
      systemPrompt.className = 'system-prompt';
      systemPrompt.innerHTML = `<h4>System Prompt:</h4><pre>${version.system_prompt}</pre>`;
      
      const outputPrompt = document.createElement('div');
      outputPrompt.className = 'output-prompt';
      outputPrompt.innerHTML = `<h4>Output Prompt:</h4><pre>${version.output_prompt}</pre>`;
      
      diffView.appendChild(systemPrompt);
      diffView.appendChild(outputPrompt);
      content.appendChild(diffView);
      
      panel.appendChild(header);
      panel.appendChild(content);
      accordion.appendChild(panel);
      
      // Toggle accordion
      header.addEventListener('click', function() {
        this.classList.toggle('active');
        const content = this.nextElementSibling;
        if (content.style.maxHeight) {
          content.style.maxHeight = null;
        } else {
          content.style.maxHeight = content.scrollHeight + 'px';
        }
      });
    });
    
    promptVersions.appendChild(accordion);
  }
});
</script>
{% endblock %}

# src/app/services/background_service.py
import numpy as np
import pandas as pd
from celery import Celery
from sqlalchemy.orm import Session
from src.app.db.database import SessionLocal
from src.app.db.ml_models import MetaLearningConfiguration
from src.app.config import settings
import joblib
import json
import os
from datetime import datetime

celery_app = Celery(
    'prompt_optimizer',
    broker=settings.CELERY_BROKER_URL,
    backend=settings.CELERY_RESULT_BACKEND
)

@celery_app.task
def train_meta_model_task(config_id, user_id):
    """Train a meta-learning model for prompt quality prediction"""
    db = SessionLocal()
    try:
        # Get the configuration
        config = db.query(MetaLearningConfiguration).filter(
            MetaLearningConfiguration.id == config_id
        ).first()
        
        if not config:
            return {"status": "error", "message": "Configuration not found"}
        
        # Get historical data for training
        # This would come from your experiment results, prompt versions, etc.
        # For example:
        experiment_data = db.query(
            # Relevant experiment data query
        ).all()
        
        if not experiment_data:
            return {"status": "error", "message": "No training data available"}
        
        # Prepare feature vectors
        X, y = prepare_training_data(experiment_data, config.feature_selection)
        
        # Train model based on configuration type
        if config.model_type == "xgboost":
            import xgboost as xgb
            model = xgb.XGBRegressor(**config.hyperparameters)
        elif config.model_type == "random_forest":
            from sklearn.ensemble import RandomForestRegressor
            model = RandomForestRegressor(**config.hyperparameters)
        else:
            return {"status": "error", "message": f"Unsupported model type: {config.model_type}"}
        
        # Train the model
        model.fit(X, y)
        
        # Evaluate performance
        from sklearn.model_selection import cross_val_score
        scores = cross_val_score(model, X, y, cv=5)
        performance = scores.mean()
        
        # Save the model
        model_path = f"models/meta/{config_id}.joblib"
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        joblib.dump(model, model_path)
        
        # Update configuration
        config.last_trained = datetime.utcnow()
        config.performance = float(performance)
        config.model_path = model_path
        db.commit()
        
        return {
            "status": "success", 
            "performance": float(performance),
            "model_path": model_path
        }
    
    except Exception as e:
        return {"status": "error", "message": str(e)}
    
    finally:
        db.close()

def prepare_training_data(experiment_data, feature_selection):
    """Prepare feature vectors and target values for training"""
    # This is a simplified example - actual implementation would depend on your data
    features = []
    targets = []
    
    for item in experiment_data:
        # Extract system_prompt and output_prompt
        system_prompt = item.system_prompt
        output_prompt = item.output_prompt
        
        # Calculate features - this depends on your feature selection
        prompt_length = len(system_prompt) + len(output_prompt)
        prompt_complexity = calculate_complexity(system_prompt)
        # ... other features
        
        feature_vector = [prompt_length, prompt_complexity]
        
        # Target value (e.g., performance metric)
        target = item.exact_match_score  # Or whatever metric you're optimizing for
        
        features.append(feature_vector)
        targets.append(target)
    
    return np.array(features), np.array(targets)

def calculate_complexity(text):
    """Calculate text complexity (example feature)"""
    # This is just a simple example - you might use more sophisticated NLP
    words = text.split()
    avg_word_length = sum(len(word) for word in words) / len(words) if words else 0
    return avg_word_length

    # src/api/endpoints/ml_settings.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from src.app.db.database import get_db
from src.app.auth import get_current_user
from src.app.services.ml_settings_service import MLSettingsService
from src.api.models import (
    ModelConfigurationCreate, 
    ModelConfigurationResponse,
    MetricConfigurationCreate,
    MetricConfigurationResponse,
    MetaLearningConfigurationCreate,
    MetaLearningConfigurationResponse
)
from typing import List

router = APIRouter(prefix="/ml-settings", tags=["ML Settings"])

@router.get("/models", response_model=List[ModelConfigurationResponse])
async def get_model_configurations(
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Get all model configurations for the current user"""
    service = MLSettingsService(db)
    return service.get_model_configurations(current_user.id)

@router.post("/models", response_model=ModelConfigurationResponse)
async def create_model_configuration(
    config: ModelConfigurationCreate,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Create a new model configuration"""
    service = MLSettingsService(db)
    return service.create_model_configuration(current_user.id, config.dict())

# Similar endpoints for metrics and meta-learning configurations...

@router.post("/meta-learning/{config_id}/train")
async def train_meta_model(
    config_id: str,
    current_user = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """Train a meta-learning model"""
    from src.app.services.background_service import train_meta_model_task
    
    # Verify the configuration exists and belongs to the user
    service = MLSettingsService(db)
    config = service.get_meta_learning_configuration(config_id)
    
    if not config or config.get("user_id") != current_user.id:
        raise HTTPException(status_code=404, detail="Configuration not found")
    
    # Start training task
    task = train_meta_model_task.delay(config_id, current_user.id)
    
    return {"status": "training_started", "task_id": task.id}

    # src/app/dashboard.py
from flask import Flask
from flask_login import LoginManager
from src.app.dashboard.ml_settings import ml_settings_bp

def create_flask_app():
    """Create Flask app for admin dashboard"""
    app = Flask(__name__, template_folder='templates', static_folder='static')
    app.config['SECRET_KEY'] = '...'  # Should use settings or Secret Manager
    
    # Configure login manager
    login_manager = LoginManager()
    login_manager.init_app(app)
    
    # Register blueprints
    app.register_blueprint(ml_settings_bp)
    
    # Main dashboard route
    @app.route('/')
    def index():
        return render_template('dashboard/index.html')
    
    return app

    /* src/app/static/css/ml_settings.css */
.ml-settings-dashboard {
  padding: 20px;
}

.card-grid {
  display: grid;
  grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
  gap: 20px;
  margin-top: 20px;
}

.card {
  background: white;
  border-radius: 8px;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  padding: 20px;
  transition: transform 0.2s, box-shadow 0.2s;
}

.card:hover {
  transform: translateY(-5px);
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
}

.card h2 {
  margin-top: 0;
  color: #333;
  font-size: 1.4rem;
}

.card p {
  color: #666;
  margin-bottom: 20px;
}

.btn {
  display: inline-block;
  padding: 8px 16px;
  background-color: #3498db;
  color: white;
  border-radius: 4px;
  text-decoration: none;
  transition: background-color 0.2s;
}

.btn:hover {
  background-color: #2980b9;
}

.btn-primary {
  background-color: #3498db;
}

.btn-danger {
  background-color: #e74c3c;
}

.btn-danger:hover {
  background-color: #c0392b;
}

.data-table {
  width: 100%;
  border-collapse: collapse;
  margin-top: 20px;
}

.data-table th, .data-table td {
  padding: 10px;
  text-align: left;
  border-bottom: 1px solid #ddd;
}

.data-table th {
  background-color: #f2f2f2;
  font-weight: bold;
}

.data-table tbody tr:hover {
  background-color: #f5f5f5;
}

.filter-bar {
  background-color: #f5f5f5;
  padding: 15px;
  border-radius: 8px;
  margin-bottom: 20px;
}

.filter-bar form {
  display: flex;
  flex-wrap: wrap;
  gap: 15px;
  align-items: flex-end;
}

.form-group {
  display: flex;
  flex-direction: column;
  gap: 5px;
}

.chart-container {
  height: 400px;
  margin: 20px 0;
}

.accordion {
  width: 100%;
  margin-top: 20px;
}

.accordion-panel {
  border: 1px solid #ddd;
  margin-bottom: 10px;
}

.accordion-header {
  background-color: #f5f5f5;
  padding: 10px 15px;
  cursor: pointer;
  font-weight: bold;
}

.accordion-header:hover {
  background-color: #e9e9e9;
}

.accordion-header.active {
  background-color: #3498db;
  color: white;
}

.accordion-content {
  padding: 0 15px;
  max-height: 0;
  overflow: hidden;
  transition: max-height 0.3s ease-out;
}

.diff-view {
  display: flex;
  flex-direction: column;
  gap: 15px;
  padding: 15px 0;
}

.diff-view pre {
  background-color: #f8f8f8;
  padding: 10px;
  border-radius: 4px;
  overflow-x: auto;
  white-space: pre-wrap;
}

.progress-bar {
  height: 20px;
  background-color: #f0f0f0;
  border-radius: 10px;
  margin: 10px 0;
  overflow: hidden;
}

.progress {
  height: 100%;
  background-color: #3498db;
  transition: width 0.3s ease;
}

.status-text {
  font-style: italic;
  color: #666;
}

.hidden {
  display: none;
}

Integration Checklist
Database Updates
[ ] Create new SQLAlchemy models for ML settings
[ ] Add relationships to existing models
[ ] Run database migrations with Alembic
Service Implementation
[ ] Implement ML settings service
[ ] Create Celery tasks for background processing
[ ] Add meta-model training functionality
UI Implementation
[ ] Create Flask routes for ML settings
[ ] Design and implement HTML templates
[ ] Add JavaScript for interactive components
[ ] Create CSS styles for ML settings pages
API Integration
[ ] Add FastAPI endpoints for ML settings
[ ] Define Pydantic models for request/response schemas
[ ] Implement authentication for all endpoints