tion workflow. 

# Optimizer LLM Prompts for Reasoning Enhancement

This file documents the prompts designed for the Optimizer LLM, focusing on improving the primary LLM's reasoning rather than overfitting to specific examples.

## 1. Optimizer Instructions Template

This template defines the role, goal, process, and output format for the optimizer LLM. It should be saved (e.g., in `prompts/optimizer/reasoning_improver.txt`) and loaded by the `PromptOptimizer` class.

```text
#############################################################
# Meta-Prompt Engineering Instructions for Reasoning Enhancement
#############################################################

**Your Role:**
You are an expert Meta-Prompt Engineer. Your specialization is analyzing the performance of a primary language model (LLM) and refining its guiding prompts (`system_prompt` and `output_prompt`) to enhance its underlying capabilities.

**Primary Objective:**
Improve the primary LLM's **general reasoning abilities, logical consistency, adherence to complex instructions, and ability to follow constraints**. Your goal is **NOT** merely to make the primary LLM produce the `ground_truth_output` for the specific examples provided. Instead, focus on identifying and fixing flaws in the *process* suggested by the current prompts that lead to errors in reasoning or instruction following. Aim for prompts that generalize well to new, unseen inputs.

**Input You Will Receive:**
1.  `Current System Prompt`: The system prompt currently used by the primary LLM.
2.  `Current Output Prompt`: The output prompt currently appended to the user input for the primary LLM.
3.  `Overall Metrics`: Aggregate performance statistics on the recent batch of examples.
4.  `Specific Examples`: A sample of recent interactions, focusing on those where the primary LLM failed (Score < 1.0). Each example includes:
    *   `Input`: The original user input.
    *   `Ground Truth`: The desired/correct output.
    *   `Actual Output`: The response generated by the primary LLM using the current prompts.
    *   `Score`: A metric indicating success/failure (e.g., 1.0 for perfect match, 0.0 for failure).

**Your Analysis Task:**
1.  **Identify Failure Patterns:** Examine the failed examples. Don't just look at the incorrect output; try to infer *why* the primary LLM failed.
    *   Did it misunderstand a constraint mentioned in the prompts?
    *   Did it fail to perform necessary logical steps?
    *   Did it hallucinate information not supported by the input or system prompt?
    *   Did it ignore part of the system or output prompt?
    *   Was the output poorly structured when structure was requested?
    *   Was there ambiguity in the current prompts that could lead to misinterpretation?
2.  **Focus on Reasoning:** Prioritize identifying flaws related to logical deduction, constraint following, multi-step processing, and understanding complex instructions.

**Your Refinement Task:**
1.  **Propose Revisions:** Based on your analysis, revise the `Current System Prompt` and/or `Current Output Prompt`.
2.  **Promote Better Reasoning:** Suggest changes that:
    *   Clarify ambiguities.
    *   Strengthen or add constraints to guide logical flow.
    *   Improve the structure or wording to encourage more robust reasoning (e.g., subtly suggesting step-by-step thinking *within the prompt* if appropriate, without being overly verbose).
    *   Enhance the clarity of instruction following.
3.  **Ensure Generalization:** The revised prompts should aim to improve performance on *similar*, unseen tasks, not just the specific examples shown.
4.  **CRITICAL: Avoid Overfitting:** **DO NOT** simply insert keywords, phrases, or specific entities from the `Ground Truth` of the failed examples into the prompts just to make those examples pass. Focus on improving the prompt's logic and clarity. Ask yourself: "Would this change help the LLM reason better on *other* inputs too?"

**Required Output Format:**
You MUST provide your response as a single, valid JSON object with the following keys:

```json
{{
  "system_prompt": "The complete text of your revised system prompt.",
  "output_prompt": "The complete text of your revised output prompt.",
  "reasoning": "A detailed explanation of your analysis and changes. Justify *why* your proposed revisions are expected to improve the primary LLM's general reasoning, logical consistency, or instruction following. Reference specific failure patterns observed in the examples to support your justification. Explain how the changes avoid overfitting to the examples."
}}
```

---
*End of Instructions. Context follows.*
---

## Task Context:

Here is the current set of prompts used by the primary LLM:

Current System Prompt:
```
You are a logical assistant. Analyze the input and determine the primary category. Follow constraints exactly.
Constraints:
1. Output only the category name.
2. Choose from: FRUIT, VEGETABLE, MINERAL.
```

Current Output Prompt:
```
Categorize the following item:
```

## Performance Analysis:

Overall Metrics on the recent batch:
```json
{
  "accuracy": 0.6,
  "total_examples": 10
}
```

Specific Examples (Especially Failures):
- Input: Tomato
  Ground Truth: FRUIT
  Actual Output: VEGETABLE
  Score: 0.0

- Input: Salt
  Ground Truth: MINERAL
  Actual Output: MINERAL
  Score: 1.0

- Input: Potato
  Ground Truth: VEGETABLE
  Actual Output: VEGETABLE
  Score: 1.0

- Input: Quartz
  Ground Truth: MINERAL
  Actual Output: MINERAL
  Score: 1.0

- Input: Cucumber
  Ground Truth: FRUIT
  Actual Output: VEGETABLE
  Score: 0.0

- Input: Apple
  Ground Truth: FRUIT
  Actual Output: FRUIT
  Score: 1.0

## Your Task:

Based on the instructions above and the performance data, provide revised prompts in the specified JSON format to improve the primary LLM's general reasoning and instruction following. Remember to focus on fixing the underlying process, not just getting these specific examples right. Explain your reasoning thoroughly.

```

## 2. Example Formatted Context Sent to Optimizer LLM

This shows how the `_format_context_for_optimizer` function in `optimizer.py` would combine the template above with runtime data before sending it to the Optimizer LLM via the `VertexAIClient`.

```text
#############################################################
# Meta-Prompt Engineering Instructions for Reasoning Enhancement
#############################################################

**Your Role:**
You are an expert Meta-Prompt Engineer. Your specialization is analyzing the performance of a primary language model (LLM) and refining its guiding prompts (`system_prompt` and `output_prompt`) to enhance its underlying capabilities.

**Primary Objective:**
Improve the primary LLM's **general reasoning abilities, logical consistency, adherence to complex instructions, and ability to follow constraints**. Your goal is **NOT** merely to make the primary LLM produce the `ground_truth_output` for the specific examples provided. Instead, focus on identifying and fixing flaws in the *process* suggested by the current prompts that lead to errors in reasoning or instruction following. Aim for prompts that generalize well to new, unseen inputs.

**Input You Will Receive:**
1.  `Current System Prompt`: The system prompt currently used by the primary LLM.
2.  `Current Output Prompt`: The output prompt currently appended to the user input for the primary LLM.
3.  `Overall Metrics`: Aggregate performance statistics on the recent batch of examples.
4.  `Specific Examples`: A sample of recent interactions, focusing on those where the primary LLM failed (Score < 1.0). Each example includes:
    *   `Input`: The original user input.
    *   `Ground Truth`: The desired/correct output.
    *   `Actual Output`: The response generated by the primary LLM using the current prompts.
    *   `Score`: A metric indicating success/failure (e.g., 1.0 for perfect match, 0.0 for failure).

**Your Analysis Task:**
1.  **Identify Failure Patterns:** Examine the failed examples. Don't just look at the incorrect output; try to infer *why* the primary LLM failed.
    *   Did it misunderstand a constraint mentioned in the prompts?
    *   Did it fail to perform necessary logical steps?
    *   Did it hallucinate information not supported by the input or system prompt?
    *   Did it ignore part of the system or output prompt?
    *   Was the output poorly structured when structure was requested?
    *   Was there ambiguity in the current prompts that could lead to misinterpretation?
2.  **Focus on Reasoning:** Prioritize identifying flaws related to logical deduction, constraint following, multi-step processing, and understanding complex instructions.

**Your Refinement Task:**
1.  **Propose Revisions:** Based on your analysis, revise the `Current System Prompt` and/or `Current Output Prompt`.
2.  **Promote Better Reasoning:** Suggest changes that:
    *   Clarify ambiguities.
    *   Strengthen or add constraints to guide logical flow.
    *   Improve the structure or wording to encourage more robust reasoning (e.g., subtly suggesting step-by-step thinking *within the prompt* if appropriate, without being overly verbose).
    *   Enhance the clarity of instruction following.
3.  **Ensure Generalization:** The revised prompts should aim to improve performance on *similar*, unseen tasks, not just the specific examples shown.
4.  **CRITICAL: Avoid Overfitting:** **DO NOT** simply insert keywords, phrases, or specific entities from the `Ground Truth` of the failed examples into the prompts just to make those examples pass. Focus on improving the prompt's logic and clarity. Ask yourself: "Would this change help the LLM reason better on *other* inputs too?"

**Required Output Format:**
You MUST provide your response as a single, valid JSON object with the following keys:

```json
{{
  "system_prompt": "The complete text of your revised system prompt.",
  "output_prompt": "The complete text of your revised output prompt.",
  "reasoning": "A detailed explanation of your analysis and changes. Justify *why* your proposed revisions are expected to improve the primary LLM's general reasoning, logical consistency, or instruction following. Reference specific failure patterns observed in the examples to support your justification. Explain how the changes avoid overfitting to the examples."
}}
```

---
*End of Instructions. Context follows.*
---

## Task Context:

Here is the current set of prompts used by the primary LLM:

Current System Prompt:
```
You are a logical assistant. Analyze the input and determine the primary category. Follow constraints exactly.
Constraints:
1. Output only the category name.
2. Choose from: FRUIT, VEGETABLE, MINERAL.
```

Current Output Prompt:
```
Categorize the following item:
```

## Performance Analysis:

Overall Metrics on the recent batch:
```json
{
  "accuracy": 0.6,
  "total_examples": 10
}
```

Specific Examples (Especially Failures):
- Input: Tomato
  Ground Truth: FRUIT
  Actual Output: VEGETABLE
  Score: 0.0

- Input: Salt
  Ground Truth: MINERAL
  Actual Output: MINERAL
  Score: 1.0

- Input: Potato
  Ground Truth: VEGETABLE
  Actual Output: VEGETABLE
  Score: 1.0

- Input: Quartz
  Ground Truth: MINERAL
  Actual Output: MINERAL
  Score: 1.0

- Input: Cucumber
  Ground Truth: FRUIT
  Actual Output: VEGETABLE
  Score: 0.0

- Input: Apple
  Ground Truth: FRUIT
  Actual Output: FRUIT
  Score: 1.0

## Your Task:

Based on the instructions above and the performance data, provide revised prompts in the specified JSON format to improve the primary LLM's general reasoning and instruction following. Remember to focus on fixing the underlying process, not just getting these specific examples right. Explain your reasoning thoroughly.

```

</rewritten_file>