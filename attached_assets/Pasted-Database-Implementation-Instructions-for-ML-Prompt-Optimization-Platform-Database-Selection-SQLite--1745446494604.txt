Database Implementation Instructions for ML Prompt Optimization Platform
Database Selection: SQLite with SQLAlchemy
SQLite is ideal for this stage because:
Zero-cost with no separate server process needed
File-based storage that's easy to version control
Sufficient performance for development and small-scale production
Seamless development-to-production transition with SQLAlchemy
Implementation Steps

1. Setup SQLAlchemy ORM and Database Connection
# src/app/database/db.py
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from pathlib import Path

# Get base directory
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent

# Environment-based configuration
DATABASE_URL = os.getenv(
    "DATABASE_URL", 
    f"sqlite:///{BASE_DIR}/data/prompt_optimizer.db"
)

# Create engine - echo=True only in development
engine = create_engine(
    DATABASE_URL, 
    echo=os.getenv("ENV", "development") == "development",
    connect_args={"check_same_thread": False} if DATABASE_URL.startswith("sqlite") else {}
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for models
Base = declarative_base()

# Dependency for routes
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()


        @ML implementation.md @PERECTworkflow.md @API_ARCHITECTURE_README.md @APIinfo.md @APIworflow @Stage4 @Stage3.md @Stage2.md @Stage1insturctions.md 
Review my current archieture and goals. write instructions for an LLM to easily make a free database for our machine learning and AI project with the correct integrations. The goal is for this stage not to cost anything. make the development and production the same. 
1. Build a Database Implementation to address these issues Currently using in-memory storage instead of persistent database
Missing proper migration and schema management

..
Database Implementation Instructions for ML Prompt Optimization Platform
Database Selection: SQLite with SQLAlchemy
SQLite is ideal for this stage because:
Zero-cost with no separate server process needed
File-based storage that's easy to version control
Sufficient performance for development and small-scale production
Seamless development-to-production transition with SQLAlchemy
Implementation Steps
1. Setup SQLAlchemy ORM and Database Connection
Apply to Data.md
# src/app/database/db.py
from sqlalchemy import create_engine
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import os
from pathlib import Path

# Get base directory
BASE_DIR = Path(__file__).resolve().parent.parent.parent.parent

# Environment-based configuration
DATABASE_URL = os.getenv(
    "DATABASE_URL", 
    f"sqlite:///{BASE_DIR}/data/prompt_optimizer.db"
)

# Create engine - echo=True only in development
engine = create_engine(
    DATABASE_URL, 
    echo=os.getenv("ENV", "development") == "development",
    connect_args={"check_same_thread": False} if DATABASE_URL.startswith("sqlite") else {}
)

# Session factory
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# Base class for models
Base = declarative_base()

# Dependency for routes
def get_db():
    db = SessionLocal()
    try:
        yield db
    finally:
        db.close()
2. Define SQLAlchemy Models
# src/app/models/database_models.py
from sqlalchemy import Column, Integer, String, ForeignKey, Float, DateTime, JSON, Text
from sqlalchemy.orm import relationship
from datetime import datetime
import uuid

from src.app.database.db import Base

def generate_uuid():
    return str(uuid.uuid4())

class Prompt(Base):
    __tablename__ = "prompts"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    system_prompt = Column(Text, nullable=False)
    output_prompt = Column(Text, nullable=False)
    version = Column(Integer, default=1)
    parent_id = Column(String, ForeignKey("prompts.id"), nullable=True)
    metadata = Column(JSON, default={})
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    parent = relationship("Prompt", remote_side=[id], backref="versions")
    experiments = relationship("Experiment", back_populates="initial_prompt")
    
class Dataset(Base):
    __tablename__ = "datasets"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    name = Column(String, nullable=False)
    file_path = Column(String, nullable=False)
    row_count = Column(Integer)
    columns = Column(JSON)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    experiments = relationship("Experiment", back_populates="dataset")

class Experiment(Base):
    __tablename__ = "experiments"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    name = Column(String, nullable=False)
    initial_prompt_id = Column(String, ForeignKey("prompts.id"), nullable=False)
    dataset_id = Column(String, ForeignKey("datasets.id"), nullable=False)
    metrics = Column(JSON, default=[])
    max_epochs = Column(Integer, default=10)
    target_threshold = Column(Float, default=0.8)
    status = Column(String, default="created")
    best_prompt_id = Column(String, ForeignKey("prompts.id"), nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    initial_prompt = relationship("Prompt", foreign_keys=[initial_prompt_id])
    best_prompt = relationship("Prompt", foreign_keys=[best_prompt_id])
    dataset = relationship("Dataset", back_populates="experiments")
    metrics_history = relationship("MetricsRecord", back_populates="experiment")

class MetricsRecord(Base):
    __tablename__ = "metrics_records"
    
    id = Column(String, primary_key=True, default=generate_uuid)
    experiment_id = Column(String, ForeignKey("experiments.id"), nullable=False)
    epoch = Column(Integer, nullable=False)
    metrics = Column(JSON, nullable=False)
    prompt_id = Column(String, ForeignKey("prompts.id"), nullable=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # Relationships
    experiment = relationship("Experiment", back_populates="metrics_history")
    prompt = relationship("Prompt")
    Adapt API Endpoints to Use Database
    Adapt API Endpoints to Use Database
    # src/api/endpoints/prompts.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from src.app.database.db import get_db
from src.app.repositories.prompt_repository import PromptRepository
from src.api.models import PromptCreate, PromptResponse
from typing import List

router = APIRouter(prefix="/prompts", tags=["Prompts"])

@router.post("/", response_model=PromptResponse)
async def create_prompt(prompt_data: PromptCreate, db: Session = Depends(get_db)):
    """Create a new prompt"""
    repo = PromptRepository(db)
    prompt = repo.create(
        system_prompt=prompt_data.system_prompt,
        output_prompt=prompt_data.output_prompt,
        metadata=prompt_data.metadata
    )
    return PromptResponse.from_orm(prompt)

@router.get("/{prompt_id}", response_model=PromptResponse)
async def get_prompt(prompt_id: str, db: Session = Depends(get_db)):
    """Get a prompt by ID"""
    repo = PromptRepository(db)
    prompt = repo.get_by_id(prompt_id)
    if not prompt:
        raise HTTPException(status_code=404, detail="Prompt not found")
    return PromptResponse.from_orm(prompt)

# Additional endpoints...
# Set up alembic directory structure
# alembic/
#   env.py
#   script.py.mako
#   versions/
#      initial_migration.py

# alembic/env.py
from logging.config import fileConfig
from sqlalchemy import engine_from_config, pool
from alembic import context
import os
import sys

# Add the src directory to the path so alembic can find the models
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

# Import the SQLAlchemy declarative Base and models
from src.app.database.db import Base
from src.app.models.database_models import Prompt, Dataset, Experiment, MetricsRecord

# Import Base.metadata to use with alembic
target_metadata = Base.metadata

# Get the database URL from the environment
config = context.config
db_url = os.getenv("DATABASE_URL", "sqlite:///data/prompt_optimizer.db")
config.set_main_option("sqlalchemy.url", db_url)

# Other alembic config...
# src/app/repositories/prompt_repository.py
from sqlalchemy.orm import Session
from typing import List, Optional, Dict, Any
from src.app.models.database_models import Prompt
from src.app.models.prompt_state import PromptState
from datetime import datetime

class PromptRepository:
    def __init__(self, db: Session):
        self.db = db
    
    def create(self, system_prompt: str, output_prompt: str, parent_id: Optional[str] = None, 
               metadata: Optional[Dict[str, Any]] = None) -> Prompt:
        """Create a new prompt record"""
        # Get version if parent exists
        version = 1
        if parent_id:
            parent = self.db.query(Prompt).filter(Prompt.id == parent_id).first()
            if parent:
                version = parent.version + 1
        
        # Create new prompt
        prompt = Prompt(
            system_prompt=system_prompt,
            output_prompt=output_prompt,
            parent_id=parent_id,
            version=version,
            metadata=metadata or {}
        )
        
        self.db.add(prompt)
        self.db.commit()
        self.db.refresh(prompt)
        return prompt
    
    def get_by_id(self, prompt_id: str) -> Optional[Prompt]:
        """Get prompt by ID"""
        return self.db.query(Prompt).filter(Prompt.id == prompt_id).first()
    
    def to_prompt_state(self, prompt: Prompt) -> PromptState:
        """Convert database model to domain model"""
        return PromptState(
            system_prompt=prompt.system_prompt,
            output_prompt=prompt.output_prompt,
            id=prompt.id,
            parent_id=prompt.parent_id,
            version=prompt.version,
            metadata=prompt.metadata,
            created_at=prompt.created_at
        )
    
    # Additional methods for listing, updating, etc.
    # src/api/endpoints/prompts.py
from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from src.app.database.db import get_db
from src.app.repositories.prompt_repository import PromptRepository
from src.api.models import PromptCreate, PromptResponse
from typing import List

router = APIRouter(prefix="/prompts", tags=["Prompts"])

@router.post("/", response_model=PromptResponse)
async def create_prompt(prompt_data: PromptCreate, db: Session = Depends(get_db)):
    """Create a new prompt"""
    repo = PromptRepository(db)
    prompt = repo.create(
        system_prompt=prompt_data.system_prompt,
        output_prompt=prompt_data.output_prompt,
        metadata=prompt_data.metadata
    )
    return PromptResponse.from_orm(prompt)

@router.get("/{prompt_id}", response_model=PromptResponse)
async def get_prompt(prompt_id: str, db: Session = Depends(get_db)):
    """Get a prompt by ID"""
    repo = PromptRepository(db)
    prompt = repo.get_by_id(prompt_id)
    if not prompt:
        raise HTTPException(status_code=404, detail="Prompt not found")
    return PromptResponse.from_orm(prompt)

# Additional endpoints...
# src/flows/prompt_optimization_flow.py
from prefect import flow, task, get_run_logger
from sqlalchemy.orm import Session
from src.app.database.db import engine, SessionLocal
from src.app.repositories.prompt_repository import PromptRepository
from src.app.repositories.experiment_repository import ExperimentRepository
from src.app.repositories.metrics_repository import MetricsRepository

@task(name="load-state-from-db")
def load_state_from_db(prompt_id: str):
    """Load prompt state from database"""
    with SessionLocal() as db:
        repo = PromptRepository(db)
        prompt = repo.get_by_id(prompt_id)
        if not prompt:
            raise ValueError(f"Prompt with ID {prompt_id} not found")
        return repo.to_prompt_state(prompt)

@task(name="save-metrics-to-db")
def save_metrics_to_db(experiment_id: str, epoch: int, metrics: dict, prompt_id: str = None):
    """Save metrics to database"""
    with SessionLocal() as db:
        repo = MetricsRepository(db)
        metrics_record = repo.create(
            experiment_id=experiment_id,
            epoch=epoch,
            metrics=metrics,
            prompt_id=prompt_id
        )
        return metrics_record.id

@flow(name="prompt-optimization-flow")
def prompt_optimization_flow(
    vertex_project_id: str,
    vertex_location: str,
    primary_model_name: str,
    optimizer_model_name: str,
    experiment_id: str,
    target_metric: str = "exact_match_score",
    target_threshold: float = 0.90,
    patience: int = 3,
    max_iterations: int = 10,
):
    """Main optimization flow that iteratively improves prompts using database persistence"""
    logger = get_run_logger()
    
    # Load experiment from database
    with SessionLocal() as db:
        exp_repo = ExperimentRepository(db)
        experiment = exp_repo.get_by_id(experiment_id)
        if not experiment:
            raise ValueError(f"Experiment with ID {experiment_id} not found")
            
        # Update experiment status
        exp_repo.update_status(experiment_id, "running")
    
    # Load initial prompt state
    current_prompt_id = experiment.initial_prompt_id
    no_improve_count = 0
    
    for iteration in range(max_iterations):
        # Load current prompt state from database
        prompt_state = load_state_from_db(current_prompt_id)
        
        # Continue with flow implementation similar to before
        # but using database repositories for persistence
        # src/flows/prompt_optimization_flow.py
from prefect import flow, task, get_run_logger
from sqlalchemy.orm import Session
from src.app.database.db import engine, SessionLocal
from src.app.repositories.prompt_repository import PromptRepository
from src.app.repositories.experiment_repository import ExperimentRepository
from src.app.repositories.metrics_repository import MetricsRepository

@task(name="load-state-from-db")
def load_state_from_db(prompt_id: str):
    """Load prompt state from database"""
    with SessionLocal() as db:
        repo = PromptRepository(db)
        prompt = repo.get_by_id(prompt_id)
        if not prompt:
            raise ValueError(f"Prompt with ID {prompt_id} not found")
        return repo.to_prompt_state(prompt)

@task(name="save-metrics-to-db")
def save_metrics_to_db(experiment_id: str, epoch: int, metrics: dict, prompt_id: str = None):
    """Save metrics to database"""
    with SessionLocal() as db:
        repo = MetricsRepository(db)
        metrics_record = repo.create(
            experiment_id=experiment_id,
            epoch=epoch,
            metrics=metrics,
            prompt_id=prompt_id
        )
        return metrics_record.id

@flow(name="prompt-optimization-flow")
def prompt_optimization_flow(
    vertex_project_id: str,
    vertex_location: str,
    primary_model_name: str,
    optimizer_model_name: str,
    experiment_id: str,
    target_metric: str = "exact_match_score",
    target_threshold: float = 0.90,
    patience: int = 3,
    max_iterations: int = 10,
):
    """Main optimization flow that iteratively improves prompts using database persistence"""
    logger = get_run_logger()
    
    # Load experiment from database
    with SessionLocal() as db:
        exp_repo = ExperimentRepository(db)
        experiment = exp_repo.get_by_id(experiment_id)
        if not experiment:
            raise ValueError(f"Experiment with ID {experiment_id} not found")
            
        # Update experiment status
        exp_repo.update_status(experiment_id, "running")
    
    # Load initial prompt state
    current_prompt_id = experiment.initial_prompt_id
    no_improve_count = 0
    
    for iteration in range(max_iterations):
        # Load current prompt state from database
        prompt_state = load_state_from_db(current_prompt_id)
        
        # Continue with flow implementation similar to before
        # but using database repositories for persistence


        # src/flows/prompt_optimization_flow.py
from prefect import flow, task, get_run_logger
from sqlalchemy.orm import Session
from src.app.database.db import engine, SessionLocal
from src.app.repositories.prompt_repository import PromptRepository
from src.app.repositories.experiment_repository import ExperimentRepository
from src.app.repositories.metrics_repository import MetricsRepository

@task(name="load-state-from-db")
def load_state_from_db(prompt_id: str):
    """Load prompt state from database"""
    with SessionLocal() as db:
        repo = PromptRepository(db)
        prompt = repo.get_by_id(prompt_id)
        if not prompt:
            raise ValueError(f"Prompt with ID {prompt_id} not found")
        return repo.to_prompt_state(prompt)

@task(name="save-metrics-to-db")
def save_metrics_to_db(experiment_id: str, epoch: int, metrics: dict, prompt_id: str = None):
    """Save metrics to database"""
    with SessionLocal() as db:
        repo = MetricsRepository(db)
        metrics_record = repo.create(
            experiment_id=experiment_id,
            epoch=epoch,
            metrics=metrics,
            prompt_id=prompt_id
        )
        return metrics_record.id

@flow(name="prompt-optimization-flow")
def prompt_optimization_flow(
    vertex_project_id: str,
    vertex_location: str,
    primary_model_name: str,
    optimizer_model_name: str,
    experiment_id: str,
    target_metric: str = "exact_match_score",
    target_threshold: float = 0.90,
    patience: int = 3,
    max_iterations: int = 10,
):
    """Main optimization flow that iteratively improves prompts using database persistence"""
    logger = get_run_logger()
    
    # Load experiment from database
    with SessionLocal() as db:
        exp_repo = ExperimentRepository(db)
        experiment = exp_repo.get_by_id(experiment_id)
        if not experiment:
            raise ValueError(f"Experiment with ID {experiment_id} not found")
            
        # Update experiment status
        exp_repo.update_status(experiment_id, "running")
    
    # Load initial prompt state
    current_prompt_id = experiment.initial_prompt_id
    no_improve_count = 0
    
    for iteration in range(max_iterations):
        # Load current prompt state from database
        prompt_state = load_state_from_db(current_prompt_id)
        
        # Continue with flow implementation similar to before
        # but using database repositories for persistence
        # src/cli.py
import click
import os
from alembic.config import Config
from alembic import command
import sys
from pathlib import Path

# Get base directory  
BASE_DIR = Path(__file__).resolve().parent.parent

@click.group()
def cli():
    """Command line interface for prompt optimizer database management"""
    pass

@cli.command()
def init_db():
    """Initialize the database and run migrations"""
    # Create data directory if it doesn't exist
    data_dir = BASE_DIR / "data"
    data_dir.mkdir(exist_ok=True)
    
    # Configure alembic
    alembic_cfg = Config(str(BASE_DIR / "alembic.ini"))
    
    # Run migrations
    command.upgrade(alembic_cfg, "head")
    click.echo("Database initialized and migrations applied")

@cli.command()
@click.argument("message")
def create_migration(message):
    """Create a new migration"""
    alembic_cfg = Config(str(BASE_DIR / "alembic.ini"))
    command.revision(alembic_cfg, autogenerate=True, message=message)
    click.echo(f"Migration created with message: {message}")

@cli.command()
def upgrade_db():
    """Upgrade database to latest migration"""
    alembic_cfg = Config(str(BASE_DIR / "alembic.ini"))
    command.upgrade(alembic_cfg, "head")
    click.echo("Database upgraded to latest migration")

if __name__ == "__main__":
    cli()
    # Database Setup Guide

## Development Environment

1. Install dependencies:
   ```
   pip install -r requirements.txt
   ```

2. Initialize the database:
   ```
   python -m src.cli init_db
   ```

3. Run the application:
   ```
   uvicorn src.app.main:app --reload
   ```

## Production Environment (Still Free)

For production, you can continue using SQLite if your application doesn't need concurrent writing:

1. Configure environment variables:
   ```
   DATABASE_URL=sqlite:///data/prompt_optimizer.db
   ENV=production
   ```

2. Initialize and upgrade the database:
   ```
   python -m src.cli init_db
   ```

3. Run with gunicorn:
   ```
   gunicorn src.app.main:app -w 1 -k uvicorn.workers.UvicornWorker
   ```

## Creating Migrations

When you make changes to models:

# Add these to requirements.txt
sqlalchemy==2.0.23
alembic==1.12.0
click==8.1.7

