Product Plan: Barebones Prompt Refiner UI
1. Goal:
To create a simple web-based UI allowing a user to iteratively test and manually refine a system_prompt and an output_prompt by running example inputs through a Vertex AI LLM and observing the outputs.
2. Core User Workflow:
User opens the web UI.
User inputs or loads an initial system_prompt and output_prompt.
User provides example data (pairs of user_input and ground_truth_output), either via CSV upload or direct text area input.
User clicks "Run Evaluation".
The backend sends each user_input (combined with the prompts) to Vertex AI.
The UI displays a table showing: user_input, ground_truth_output, model_response, and a simple evaluation metric (e.g., Exact Match).
User reviews the results, manually edits the system_prompt and/or output_prompt in the UI based on observed successes/failures.
User repeats steps 4-7 until satisfied with the prompt performance.
(Optional) User can save the refined prompts.
3. Architecture Overview:
Frontend: Simple single-page web application (HTML, CSS, JavaScript).
Backend: Python web server (Flask) handling UI requests, orchestrating calls to Vertex AI, performing basic evaluation, and serving the frontend.
LLM: Google Cloud Vertex AI (e.g., Gemini models).
4. Codebase Structure:
Apply to MLprompt
prompt-refiner/
│
├── app/                  # Main application source code
│   ├── static/           # CSS, JavaScript files
│   │   ├── style.css
│   │   └── script.js
│   ├── templates/        # HTML templates (Jinja2)
│   │   └── index.html
│   ├── __init__.py
│   ├── main.py           # Flask application routes and logic
│   ├── llm_client.py     # Vertex AI interaction module
│   ├── evaluator.py      # Simple evaluation logic (e.g., exact match)
│   └── utils.py          # Helper functions (e.g., data parsing)
│
├── data/                 # Directory for user-uploaded data (optional, can be in-memory)
│   └── examples.csv      # Example data file format
│
├── prompts/              # Directory to save refined prompts (optional)
│   ├── system_prompt_v1.txt
│   └── output_prompt_v1.txt
│
├── config.yaml           # Configuration (Vertex AI project, model, etc.)
├── requirements.txt      # Python dependencies
└── README.md             # Project description and setup instructions
5. Frontend Details (app/templates/index.html, app/static/):
UI Elements:
Two large <textarea> elements for system_prompt and output_prompt.
Input method for example data:
Option A: <input type="file"> for CSV upload (user_input, ground_truth_output).
Option B: A <textarea> expecting structured input (e.g., CSV format or JSON).
A "Run Evaluation" <button>.
A results area (e.g., an HTML <table>) to display user_input, ground_truth_output, model_response, score.
(Optional) "Save Prompts" button.
Logic (script.js):
Use fetch API to send prompts and example data to the backend /run endpoint.
Parse the JSON response from the backend.
Dynamically update the results table/area with the received data.
Handle data input (reading from file or text area).
6. Backend Details (app/main.py, app/llm_client.py, app/evaluator.py):
Framework: Flask.
Endpoints:
GET /: Serves the main index.html page.
POST /run:
Accepts JSON payload containing system_prompt, output_prompt, and examples (list of {user_input, ground_truth_output}).
Parses input data.
For each example: Calls llm_client.get_llm_response().
For each response: Calls evaluator.calculate_score().
Returns JSON response { results: [{user_input, ground_truth_output, model_response, score}, ...] }.
POST /save_prompt (Optional):
Accepts JSON payload with prompts.
Saves prompts to files in the prompts/ directory with versioning/timestamps.
Vertex AI Client (llm_client.py):
Uses google-cloud-aiplatform library.
Reads project_id, location, model_name from config.yaml.
Initializes Vertex AI client (aiplatform.init(...)).
Loads the specified model (GenerativeModel(...)).
get_llm_response(system_prompt, user_input, output_prompt) function:
Constructs the appropriate message list/payload for the Vertex AI API (e.g., using system_prompt and combining user_input + output_prompt for the user turn).
Calls model.generate_content(...) with temperature=0 (for reproducibility during refinement).
Includes error handling (e.g., API errors, rate limits).
Extracts and returns the text response.
Evaluator (evaluator.py):
calculate_score(model_response, ground_truth_output) function:
Implements simple logic, e.g., return 1 if model_response.strip() == ground_truth_output.strip() else 0.
Configuration (config.yaml):
Stores Vertex AI project_id, location, model_name (e.g., gemini-1.5-pro-preview-0409).
Loaded using PyYAML.
7. Key Libraries (requirements.txt):
Flask: Web framework.
google-cloud-aiplatform: Vertex AI SDK.
PyYAML: For loading configuration.
pandas: (Optional) If supporting CSV uploads for easier data handling.
8. Vertex AI Integration:
Authentication: Relies on Application Default Credentials (ADC). The environment running the Flask app needs to be authenticated to GCP (e.g., run gcloud auth application-default login locally, or use service account keys/metadata server in deployed environments).
API Usage: Primarily uses the Generative Model (generate_content) API within the google-cloud-aiplatform library.
Model Selection: Configurable via config.yaml to allow trying different Vertex AI models.
9. Next Steps / MVP Focus:
Set up the basic Flask application structure.
Implement the core llm_client.py to connect to Vertex AI and get a single response.
Create the basic HTML structure (index.html) with text areas and a run button.
Implement the /run endpoint logic (without data input handling initially).
Add basic JavaScript (script.js) to call /run and display a single result.
Implement data input handling (e.g., text area parsing) and loop through examples.
Add the evaluator.py and display scores.
Refine UI/UX (styling, error handling).
(Post-MVP) Add CSV upload, prompt saving.
This plan provides a clear path to building the requested barebones UI, focusing on manual prompt refinement with Vertex AI integration, while borrowing organizational best practices from the provided documents.