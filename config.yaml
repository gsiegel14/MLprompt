# Prompt ML Platform Configuration

# Google Gemini API Configuration
gemini:
  model_name: "gemini-1.0-pro"  # Free tier model
  temperature: 0.0
  top_p: 0.95
  top_k: 40
  max_output_tokens: 1024

# Application Configuration
app:
  max_examples: 0  # 0 means no limit
  enable_caching: true
  debug: true

# Optimizer Configuration
optimizer:
  model_name: "gemini-1.0-pro"  # Free tier model
  temperature: 0.7  # Higher temperature for more creative prompt improvements
  max_output_tokens: 2048
  strategies:
    - "reasoning_first"  # Reasoning-First Refinement approach
    - "full_rewrite"  # Complete prompt rewrite
    - "targeted_edit"  # Specific changes to problematic sections
    - "example_addition"  # Add few-shot examples to prompts

# Evaluation Configuration
evaluation:
  metrics:
    - "exact_match"  # Perfect match (1.0)
    - "semantic_similarity"  # Similar meaning
    - "keyword_match"  # Contains key elements
  perfect_threshold: 0.9  # Score threshold for "perfect" match

# Training Configuration
training:
  default_train_ratio: 0.8  # Default train/validation split
  default_max_iterations: 5  # Default number of optimization rounds
  early_stopping_patience: 2  # Stop if no improvement after N iterations