import os
import csv
import json
import random
import logging
import pandas as pd
from typing import List, Dict, Any, Tuple, Optional

from app.utils import parse_text_examples, parse_csv_file

logger = logging.getLogger(__name__)

class DataModule:
    """
    Handles dataset management for prompt optimization, including loading,
    train/validation splitting, and batch creation.
    """

    def _load_examples_from_file(self, file_path):
        """Load examples from a JSON file."""
        if os.path.exists(file_path):
            try:
                with open(file_path, 'r') as f:
                    examples = json.load(f)
                    if examples:
                        logger.debug(f"Loaded {len(examples)} examples from {file_path}")
                        return examples
                    else:
                        logger.warning(f"File {file_path} exists but contains no examples")
            except Exception as e:
                logger.error(f"Error loading examples from {file_path}: {e}")
        else:
            logger.warning(f"Examples file {file_path} does not exist")
        return []
    
    def _save_examples(self, examples, file_path):
        """Save examples to a JSON file."""
        try:
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            with open(file_path, 'w') as f:
                json.dump(examples, f, indent=2)
            logger.debug(f"Saved {len(examples)} examples to {file_path}")
            return True
        except Exception as e:
            logger.error(f"Error saving examples to {file_path}: {e}")
            return False

    def __init__(self, base_dir='data'):
        self.base_dir = base_dir
        self.train_dir = os.path.join(base_dir, 'train')
        self.validation_dir = os.path.join(base_dir, 'validation')

        # Create directories if they don't exist
        os.makedirs(self.train_dir, exist_ok=True)
        os.makedirs(self.validation_dir, exist_ok=True)

        self.train_examples = []
        self.validation_examples = []

        # Load train and validation examples
        train_file = os.path.join(self.train_dir, 'current_train.json')
        validation_file = os.path.join(self.validation_dir, 'current_validation.json')

        # Try to load from current files first
        self.train_examples = self._load_examples_from_file(train_file)
        self.validation_examples = self._load_examples_from_file(validation_file)

        # If current files are empty, try examples.json
        if not self.train_examples:
            alt_train_file = os.path.join(self.train_dir, 'examples.json')
            self.train_examples = self._load_examples_from_file(alt_train_file)
            if self.train_examples:
                # Copy to current_train.json
                self._save_examples(self.train_examples, train_file)
                logger.info(f"Updated {train_file} with {len(self.train_examples)} examples")

        if not self.validation_examples:
            alt_validation_file = os.path.join(self.validation_dir, 'examples.json')
            self.validation_examples = self._load_examples_from_file(alt_validation_file)
            if self.validation_examples:
                # Copy to current_validation.json
                self._save_examples(self.validation_examples, validation_file)
                logger.info(f"Updated {validation_file} with {len(self.validation_examples)} examples")

        logger.info(f"Initialized DataModule with {len(self.train_examples)} train examples and {len(self.validation_examples)} validation examples")

    def load_examples_from_text(self, text_content: str, train_ratio: float = 0.8) -> Tuple[List, List]:
        """
        Load examples from text content and split into train/validation sets.

        Args:
            text_content (str): Text with examples in CSV format
            train_ratio (float): Ratio of examples to use for training

        Returns:
            tuple: (train_examples, validation_examples)
        """
        examples = parse_text_examples(text_content)
        return self.split_examples(examples, train_ratio)

    def load_examples_from_csv(self, file_path: str, train_ratio: float = 0.8) -> Tuple[List, List]:
        """
        Load examples from a CSV file and split into train/validation sets.

        Args:
            file_path (str): Path to the CSV file
            train_ratio (float): Ratio of examples to use for training

        Returns:
            tuple: (train_examples, validation_examples)
        """
        with open(file_path, 'rb') as f:
            examples = parse_csv_file(f)

        return self.split_examples(examples, train_ratio)

    def split_examples(self, examples: List[Dict[str, str]], train_ratio: float = 0.8) -> Tuple[List, List]:
        """
        Split examples into training and validation sets.

        Args:
            examples (list): List of example dictionaries
            train_ratio (float): Ratio of examples to use for training

        Returns:
            tuple: (train_examples, validation_examples)
        """
        if not examples:
            logger.warning("No examples to split")
            return [], []

        # Shuffle the examples
        random.shuffle(examples)
        
        # Calculate the split point
        split_idx = int(len(examples) * train_ratio)
        
        # Split the examples
        train_examples = examples[:split_idx]
        validation_examples = examples[split_idx:]
        
        # Save the examples
        self._save_examples(
            train_examples, 
            os.path.join(self.train_dir, 'current_train.json')
        )
        self._save_examples(
            validation_examples, 
            os.path.join(self.validation_dir, 'current_validation.json')
        )
        
        # Update internal state
        self.train_examples = train_examples
        self.validation_examples = validation_examples
        
        logger.info(f"Split {len(examples)} examples into {len(train_examples)} training and {len(validation_examples)} validation examples")
        
        return train_examples, validation_examples

    def get_batch(self, batch_size: int = 10, validation: bool = False) -> List[Dict[str, Any]]:
        """
        Get a batch of examples for training or validation.

        Args:
            batch_size (int): Batch size to return
            validation (bool): Whether to use validation examples

        Returns:
            list: Batch of examples
        """
        if validation:
            examples = self.validation_examples
        else:
            examples = self.train_examples
            
        if not examples:
            logger.warning(f"No {'validation' if validation else 'training'} examples available when calling get_batch")
            # Try reloading examples from file
            if validation:
                examples_file = os.path.join(self.validation_dir, 'current_validation.json')
                self.validation_examples = self._load_examples_from_file(examples_file)
                examples = self.validation_examples
            else:
                examples_file = os.path.join(self.train_dir, 'current_train.json')
                self.train_examples = self._load_examples_from_file(examples_file)
                examples = self.train_examples
                
        logger.info(f"After reload attempt, have {len(examples)} {'validation' if validation else 'training'} examples")
                
        if not examples:
            return []
            
        # Return up to batch_size examples (randomly sampled if more available)
        if len(examples) <= batch_size:
            return examples
        else:
            return random.sample(examples, batch_size)
    
    def save_dataset(self, examples: List[Dict[str, str]], name: str) -> str:
        """
        Save a dataset with a given name.

        Args:
            examples (list): List of example dictionaries
            name (str): Name for the dataset

        Returns:
            str: Path to saved file
        """
        file_path = os.path.join(self.base_dir, f"{name}.json")
        self._save_examples(examples, file_path)
        return file_path

    def load_dataset(self, name: str) -> List[Dict[str, str]]:
        """
        Load a dataset by name.

        Args:
            name (str): Dataset name

        Returns:
            list: List of example dictionaries
        """
        file_path = os.path.join(self.base_dir, f"{name}.json")

        if not os.path.exists(file_path):
            logger.warning(f"Dataset {name} not found at {file_path}")
            return []

        try:
            with open(file_path, 'r') as f:
                examples = json.load(f)
            return examples
        except Exception as e:
            logger.error(f"Error loading dataset {name}: {e}")
            return []

    def export_to_csv(self, examples: List[Dict[str, str]], file_path: str) -> bool:
        """
        Export examples to a CSV file.

        Args:
            examples (list): List of example dictionaries
            file_path (str): Path to save the CSV file

        Returns:
            bool: Success status
        """
        try:
            df = pd.DataFrame(examples)
            df.to_csv(file_path, index=False)
            return True
        except Exception as e:
            logger.error(f"Error exporting to CSV: {e}")
            return False